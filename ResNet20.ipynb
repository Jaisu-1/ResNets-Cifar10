{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ResNet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP1MmCTTIY+r2Yib6/dvKTX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jaisu-1/ResNets-Cifar10/blob/master/ResNet20.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6B95Hb6YVgPZ",
        "colab": {}
      },
      "source": [
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0lj2h5FjM2T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import argparse\n",
        "import os\n",
        "import shutil\n",
        "import time\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.nn.init as init\n",
        "\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import torch.nn.parallel\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.optim\n",
        "import torch.utils.data\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "\n",
        "import torchvision\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torchvision import datasets, transforms"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XC3_uOd61D0B",
        "colab_type": "code",
        "outputId": "baba38eb-22a1-4da3-fc46-7489b68b8520",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "device = 'cuda'\n",
        "torch.cuda.is_available()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fazceH_McIQX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tb = SummaryWriter()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-2wdi8y0T2R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cost_list = []\n",
        "precision_list = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EhGsOR1W3829",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    #print(classname)\n",
        "    if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d):\n",
        "        init.kaiming_normal_(m.weight)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5owvaP740VW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LambdaLayer(nn.Module):\n",
        "    def __init__(self, lambd):\n",
        "        super(LambdaLayer, self).__init__()\n",
        "        self.lambd = lambd\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.lambd(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOqoU6SX4233",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1, option='A'):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != planes:\n",
        "            if option == 'A':\n",
        "                \"\"\"\n",
        "                For CIFAR10 ResNet paper uses option A.\n",
        "                \"\"\"\n",
        "                self.shortcut = LambdaLayer(lambda x:\n",
        "                                            F.pad(x[:, :, ::2, ::2], (0, 0, 0, 0, planes//4, planes//4), \"constant\", 0))\n",
        "            elif option == 'B':\n",
        "                self.shortcut = nn.Sequential(\n",
        "                     nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n",
        "                     nn.BatchNorm2d(self.expansion * planes)\n",
        "                )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtdgRNFE49kn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=10):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_planes = 16\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(16)\n",
        "        self.layer1 = self._make_layer(block, 16, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 32, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 64, num_blocks[2], stride=2)\n",
        "        self.linear = nn.Linear(64, num_classes)\n",
        "\n",
        "        self.apply(_weights_init)\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes * block.expansion\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = F.avg_pool2d(out, out.size()[3])\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdccSt3t5BaU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def resnet20():\n",
        "    return ResNet(BasicBlock, [3, 3, 3])\n",
        "\n",
        "\n",
        "def resnet32():\n",
        "    return ResNet(BasicBlock, [5, 5, 5])\n",
        "\n",
        "\n",
        "def resnet44():\n",
        "    return ResNet(BasicBlock, [7, 7, 7])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-o7plHy5GMW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(net):\n",
        "    import numpy as np\n",
        "    total_params = 0\n",
        "\n",
        "    for x in filter(lambda p: p.requires_grad, net.parameters()):\n",
        "        total_params += np.prod(x.data.numpy().shape)\n",
        "    print(\"Total number of params\", total_params)\n",
        "    print(\"Total layers\", len(list(filter(lambda p: p.requires_grad and len(p.data.size())>1, net.parameters()))))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owWuttwp5nFM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "workers = 4\n",
        "epochs = 200\n",
        "start_epochs = 0\n",
        "batch_size = 128\n",
        "lr = 0.1\n",
        "momentum = 0.9\n",
        "weight_decay = 1e-4\n",
        "print_freq = 50\n",
        "save_every = 10\n",
        "best_prec1 = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Z6Jtfb17nwB",
        "colab_type": "code",
        "outputId": "620a2ce5-f253-4f28-ef0a-7ae02ba37e6b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = torch.nn.DataParallel(resnet20())\n",
        "model.cuda()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataParallel(\n",
              "  (module): ResNet(\n",
              "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (layer1): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (shortcut): Sequential()\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (shortcut): Sequential()\n",
              "      )\n",
              "      (2): BasicBlock(\n",
              "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (shortcut): Sequential()\n",
              "      )\n",
              "    )\n",
              "    (layer2): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (shortcut): LambdaLayer()\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (shortcut): Sequential()\n",
              "      )\n",
              "      (2): BasicBlock(\n",
              "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (shortcut): Sequential()\n",
              "      )\n",
              "    )\n",
              "    (layer3): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (shortcut): LambdaLayer()\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (shortcut): Sequential()\n",
              "      )\n",
              "      (2): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (shortcut): Sequential()\n",
              "      )\n",
              "    )\n",
              "    (linear): Linear(in_features=64, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIA4Jj-V8lbi",
        "colab_type": "code",
        "outputId": "70bad1ec-d3dd-4c3f-86b6-8c7920ae6c5d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cudnn.benchmark = True\n",
        "\n",
        "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                     std=[0.229, 0.224, 0.225])\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "        datasets.CIFAR10(root='./data', train=True, transform=transforms.Compose([\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.RandomCrop(32, 4),\n",
        "            transforms.ToTensor(),\n",
        "            normalize,\n",
        "        ]), download=True),\n",
        "        batch_size=batch_size, shuffle=True,\n",
        "        num_workers=workers, pin_memory=True)\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "        datasets.CIFAR10(root='./data', train=False, transform=transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            normalize,\n",
        "        ])),\n",
        "        batch_size=128, shuffle=False,\n",
        "        num_workers=workers, pin_memory=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3SmHK2HF9aPt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.CrossEntropyLoss().cuda()\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr,\n",
        "                                momentum=momentum,\n",
        "                                weight_decay=weight_decay)\n",
        "\n",
        "lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer,\n",
        "              milestones=[100, 150], last_epoch=start_epochs - 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dABcdsVP_X5e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsWAvFIS_Mnh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(train_loader, model, criterion, optimizer, epoch):\n",
        "    \"\"\"\n",
        "        Run one train epoch\n",
        "    \"\"\"\n",
        "    batch_time = AverageMeter()\n",
        "    data_time = AverageMeter()\n",
        "    losses = AverageMeter()\n",
        "    top1 = AverageMeter()\n",
        "\n",
        "    # switch to train mode\n",
        "    model.train()\n",
        "\n",
        "    end = time.time()\n",
        "    for i, (input, target) in enumerate(train_loader):\n",
        "\n",
        "        # measure data loading time\n",
        "        data_time.update(time.time() - end)\n",
        "\n",
        "        target = target.cuda()\n",
        "        input_var = input.cuda()\n",
        "        target_var = target\n",
        "\n",
        "        # compute output\n",
        "        output = model(input_var)\n",
        "        loss = criterion(output, target_var)\n",
        "\n",
        "        # compute gradient and do SGD step\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        output = output.float()\n",
        "        loss = loss.float()\n",
        "        # measure accuracy and record loss\n",
        "        prec1 = accuracy(output.data, target)[0]\n",
        "        losses.update(loss.item(), input.size(0))\n",
        "        top1.update(prec1.item(), input.size(0))\n",
        "\n",
        "        # measure elapsed time\n",
        "        batch_time.update(time.time() - end)\n",
        "        end = time.time()\n",
        "\n",
        "        if i % print_freq == 0:\n",
        "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
        "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
        "                  'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
        "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
        "                  'Prec@1 {top1.val:.3f} ({top1.avg:.3f})'.format(\n",
        "                      epoch, i, len(train_loader), batch_time=batch_time,\n",
        "                      data_time=data_time, loss=losses, top1=top1))\n",
        "        \n",
        "    cost_list.append(losses.val)\n",
        "    precision_list.append(top1.val)\n",
        "    tb.add_scalar('Loss', losses.val, epoch)\n",
        "    tb.add_scalar('Precision', top1.val, epoch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29WJsCrm_RMf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def validate(val_loader, model, criterion):\n",
        "    \"\"\"\n",
        "    Run evaluation\n",
        "    \"\"\"\n",
        "    batch_time = AverageMeter()\n",
        "    losses = AverageMeter()\n",
        "    top1 = AverageMeter()\n",
        "\n",
        "    # switch to evaluate mode\n",
        "    model.eval()\n",
        "\n",
        "    end = time.time()\n",
        "    with torch.no_grad():\n",
        "        for i, (input, target) in enumerate(val_loader):\n",
        "            target = target.cuda()\n",
        "            input_var = input.cuda()\n",
        "            target_var = target.cuda()\n",
        "\n",
        "            # compute output\n",
        "            output = model(input_var)\n",
        "            loss = criterion(output, target_var)\n",
        "\n",
        "            output = output.float()\n",
        "            loss = loss.float()\n",
        "\n",
        "            # measure accuracy and record loss\n",
        "            prec1 = accuracy(output.data, target)[0]\n",
        "            losses.update(loss.item(), input.size(0))\n",
        "            top1.update(prec1.item(), input.size(0))\n",
        "\n",
        "            # measure elapsed time\n",
        "            batch_time.update(time.time() - end)\n",
        "            end = time.time()\n",
        "\n",
        "            if i % print_freq == 0:\n",
        "                print('Test: [{0}/{1}]\\t'\n",
        "                      'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
        "                      'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
        "                      'Prec@1 {top1.val:.3f} ({top1.avg:.3f})'.format(\n",
        "                          i, len(val_loader), batch_time=batch_time, loss=losses,\n",
        "                          top1=top1))\n",
        "\n",
        "    print(' * Prec@1 {top1.avg:.3f}'\n",
        "          .format(top1=top1))\n",
        "\n",
        "    return top1.avg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BrTACfg8_dng",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def accuracy(output, target, topk=(1,)):\n",
        "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
        "    maxk = max(topk)\n",
        "    batch_size = target.size(0)\n",
        "\n",
        "    _, pred = output.topk(maxk, 1, True, True)\n",
        "    pred = pred.t()\n",
        "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
        "\n",
        "    res = []\n",
        "    for k in topk:\n",
        "        correct_k = correct[:k].view(-1).float().sum(0)\n",
        "        res.append(correct_k.mul_(100.0 / batch_size))\n",
        "    return res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScBc4BMmIJIx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_checkpoint(state, is_best, filename = 'checkpoint.pth'):\n",
        "  torch.save(state, filename)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jpa5Dt8-q6V",
        "colab_type": "code",
        "outputId": "93cc8edc-5a1b-4870-b57f-435800b72a8f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for epoch in range(start_epochs, epochs):\n",
        "\n",
        "        # train for one epoch\n",
        "        print('current lr {:.5e}'.format(optimizer.param_groups[0]['lr']))\n",
        "        train(train_loader, model, criterion, optimizer, epoch)\n",
        "        lr_scheduler.step()\n",
        "\n",
        "        # evaluate on validation set\n",
        "        prec1 = validate(val_loader, model, criterion)\n",
        "\n",
        "        # remember best prec@1 and save checkpoint\n",
        "        is_best = prec1 > best_prec1\n",
        "        best_prec1 = max(prec1, best_prec1)\n",
        "\n",
        "        if epoch > 0 and epoch % save_every == 0:\n",
        "            save_checkpoint({\n",
        "                'epoch': epoch + 1,\n",
        "                'state_dict': model.state_dict(),\n",
        "                'best_prec1': best_prec1,\n",
        "            }, is_best)\n",
        "\n",
        "        save_checkpoint({\n",
        "            'state_dict': model.state_dict(),\n",
        "            'best_prec1': best_prec1,\n",
        "        }, is_best)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "current lr 1.00000e-01\n",
            "Epoch: [0][0/391]\tTime 0.461 (0.461)\tData 0.298 (0.298)\tLoss 3.6793 (3.6793)\tPrec@1 7.812 (7.812)\n",
            "Epoch: [0][50/391]\tTime 0.034 (0.042)\tData 0.003 (0.007)\tLoss 1.9153 (2.3877)\tPrec@1 28.906 (21.048)\n",
            "Epoch: [0][100/391]\tTime 0.028 (0.037)\tData 0.000 (0.004)\tLoss 1.7437 (2.1027)\tPrec@1 28.906 (25.897)\n",
            "Epoch: [0][150/391]\tTime 0.034 (0.037)\tData 0.000 (0.003)\tLoss 1.6479 (1.9813)\tPrec@1 35.938 (28.715)\n",
            "Epoch: [0][200/391]\tTime 0.024 (0.037)\tData 0.000 (0.002)\tLoss 1.5329 (1.8997)\tPrec@1 44.531 (31.009)\n",
            "Epoch: [0][250/391]\tTime 0.027 (0.036)\tData 0.000 (0.002)\tLoss 1.4596 (1.8321)\tPrec@1 41.406 (33.164)\n",
            "Epoch: [0][300/391]\tTime 0.038 (0.036)\tData 0.004 (0.002)\tLoss 1.3721 (1.7713)\tPrec@1 50.000 (35.270)\n",
            "Epoch: [0][350/391]\tTime 0.037 (0.036)\tData 0.003 (0.002)\tLoss 1.2580 (1.7224)\tPrec@1 53.906 (37.097)\n",
            "Test: [0/79]\tTime 0.245 (0.245)\tLoss 1.6619 (1.6619)\tPrec@1 46.094 (46.094)\n",
            "Test: [50/79]\tTime 0.012 (0.026)\tLoss 1.5789 (1.6975)\tPrec@1 41.406 (44.041)\n",
            " * Prec@1 44.260\n",
            "current lr 1.00000e-01\n",
            "Epoch: [1][0/391]\tTime 0.338 (0.338)\tData 0.293 (0.293)\tLoss 1.4034 (1.4034)\tPrec@1 50.781 (50.781)\n",
            "Epoch: [1][50/391]\tTime 0.041 (0.040)\tData 0.000 (0.006)\tLoss 1.4211 (1.3230)\tPrec@1 48.438 (52.880)\n",
            "Epoch: [1][100/391]\tTime 0.028 (0.037)\tData 0.000 (0.004)\tLoss 1.2284 (1.2676)\tPrec@1 51.562 (54.618)\n",
            "Epoch: [1][150/391]\tTime 0.031 (0.036)\tData 0.000 (0.003)\tLoss 1.2173 (1.2378)\tPrec@1 52.344 (55.464)\n",
            "Epoch: [1][200/391]\tTime 0.028 (0.036)\tData 0.000 (0.002)\tLoss 1.0247 (1.2207)\tPrec@1 63.281 (56.025)\n",
            "Epoch: [1][250/391]\tTime 0.042 (0.035)\tData 0.000 (0.002)\tLoss 0.9418 (1.1996)\tPrec@1 64.844 (56.748)\n",
            "Epoch: [1][300/391]\tTime 0.020 (0.035)\tData 0.000 (0.002)\tLoss 1.0552 (1.1850)\tPrec@1 64.844 (57.260)\n",
            "Epoch: [1][350/391]\tTime 0.035 (0.035)\tData 0.000 (0.002)\tLoss 1.0376 (1.1623)\tPrec@1 64.062 (58.048)\n",
            "Test: [0/79]\tTime 0.204 (0.204)\tLoss 1.1843 (1.1843)\tPrec@1 60.938 (60.938)\n",
            "Test: [50/79]\tTime 0.017 (0.025)\tLoss 1.4955 (1.3948)\tPrec@1 46.875 (53.462)\n",
            " * Prec@1 53.130\n",
            "current lr 1.00000e-01\n",
            "Epoch: [2][0/391]\tTime 0.297 (0.297)\tData 0.246 (0.246)\tLoss 1.1276 (1.1276)\tPrec@1 60.938 (60.938)\n",
            "Epoch: [2][50/391]\tTime 0.036 (0.040)\tData 0.000 (0.007)\tLoss 0.9995 (1.0217)\tPrec@1 65.625 (63.434)\n",
            "Epoch: [2][100/391]\tTime 0.031 (0.036)\tData 0.000 (0.004)\tLoss 0.9558 (1.0026)\tPrec@1 67.188 (64.380)\n",
            "Epoch: [2][150/391]\tTime 0.024 (0.036)\tData 0.001 (0.003)\tLoss 0.9785 (0.9868)\tPrec@1 69.531 (64.921)\n",
            "Epoch: [2][200/391]\tTime 0.047 (0.036)\tData 0.000 (0.002)\tLoss 1.1289 (0.9786)\tPrec@1 64.844 (65.435)\n",
            "Epoch: [2][250/391]\tTime 0.038 (0.036)\tData 0.000 (0.002)\tLoss 0.9574 (0.9674)\tPrec@1 62.500 (65.550)\n",
            "Epoch: [2][300/391]\tTime 0.043 (0.036)\tData 0.000 (0.002)\tLoss 0.9282 (0.9579)\tPrec@1 64.062 (65.949)\n",
            "Epoch: [2][350/391]\tTime 0.020 (0.035)\tData 0.000 (0.002)\tLoss 0.8848 (0.9529)\tPrec@1 69.531 (66.092)\n",
            "Test: [0/79]\tTime 0.201 (0.201)\tLoss 0.8378 (0.8378)\tPrec@1 68.750 (68.750)\n",
            "Test: [50/79]\tTime 0.016 (0.026)\tLoss 1.0015 (0.9371)\tPrec@1 67.188 (66.805)\n",
            " * Prec@1 66.580\n",
            "current lr 1.00000e-01\n",
            "Epoch: [3][0/391]\tTime 0.283 (0.283)\tData 0.250 (0.250)\tLoss 0.8079 (0.8079)\tPrec@1 69.531 (69.531)\n",
            "Epoch: [3][50/391]\tTime 0.034 (0.039)\tData 0.003 (0.006)\tLoss 0.9142 (0.8315)\tPrec@1 64.062 (70.021)\n",
            "Epoch: [3][100/391]\tTime 0.020 (0.037)\tData 0.000 (0.004)\tLoss 0.9238 (0.8346)\tPrec@1 72.656 (70.096)\n",
            "Epoch: [3][150/391]\tTime 0.039 (0.036)\tData 0.000 (0.003)\tLoss 0.7864 (0.8325)\tPrec@1 74.219 (70.354)\n",
            "Epoch: [3][200/391]\tTime 0.020 (0.035)\tData 0.000 (0.002)\tLoss 0.8224 (0.8306)\tPrec@1 70.312 (70.406)\n",
            "Epoch: [3][250/391]\tTime 0.020 (0.035)\tData 0.000 (0.002)\tLoss 0.8290 (0.8313)\tPrec@1 68.750 (70.443)\n",
            "Epoch: [3][300/391]\tTime 0.021 (0.035)\tData 0.000 (0.002)\tLoss 0.8031 (0.8209)\tPrec@1 75.781 (70.886)\n",
            "Epoch: [3][350/391]\tTime 0.040 (0.035)\tData 0.001 (0.002)\tLoss 0.7322 (0.8124)\tPrec@1 76.562 (71.241)\n",
            "Test: [0/79]\tTime 0.204 (0.204)\tLoss 0.6129 (0.6129)\tPrec@1 75.000 (75.000)\n",
            "Test: [50/79]\tTime 0.021 (0.026)\tLoss 0.8466 (0.7963)\tPrec@1 68.750 (72.779)\n",
            " * Prec@1 72.820\n",
            "current lr 1.00000e-01\n",
            "Epoch: [4][0/391]\tTime 0.256 (0.256)\tData 0.210 (0.210)\tLoss 0.9038 (0.9038)\tPrec@1 65.625 (65.625)\n",
            "Epoch: [4][50/391]\tTime 0.040 (0.039)\tData 0.000 (0.006)\tLoss 0.5907 (0.7093)\tPrec@1 79.688 (75.061)\n",
            "Epoch: [4][100/391]\tTime 0.043 (0.036)\tData 0.000 (0.004)\tLoss 0.6765 (0.7210)\tPrec@1 75.000 (74.590)\n",
            "Epoch: [4][150/391]\tTime 0.040 (0.035)\tData 0.000 (0.003)\tLoss 0.7106 (0.7224)\tPrec@1 72.656 (74.752)\n",
            "Epoch: [4][200/391]\tTime 0.022 (0.035)\tData 0.000 (0.002)\tLoss 0.6596 (0.7191)\tPrec@1 75.781 (74.949)\n",
            "Epoch: [4][250/391]\tTime 0.033 (0.035)\tData 0.000 (0.002)\tLoss 0.6032 (0.7150)\tPrec@1 78.125 (75.084)\n",
            "Epoch: [4][300/391]\tTime 0.023 (0.034)\tData 0.000 (0.002)\tLoss 0.7900 (0.7125)\tPrec@1 75.781 (75.171)\n",
            "Epoch: [4][350/391]\tTime 0.021 (0.034)\tData 0.000 (0.002)\tLoss 0.7269 (0.7108)\tPrec@1 74.219 (75.229)\n",
            "Test: [0/79]\tTime 0.207 (0.207)\tLoss 0.6517 (0.6517)\tPrec@1 75.000 (75.000)\n",
            "Test: [50/79]\tTime 0.016 (0.026)\tLoss 0.8631 (0.7507)\tPrec@1 71.875 (74.831)\n",
            " * Prec@1 74.250\n",
            "current lr 1.00000e-01\n",
            "Epoch: [5][0/391]\tTime 0.252 (0.252)\tData 0.204 (0.204)\tLoss 0.8238 (0.8238)\tPrec@1 70.312 (70.312)\n",
            "Epoch: [5][50/391]\tTime 0.041 (0.041)\tData 0.000 (0.008)\tLoss 0.7877 (0.6670)\tPrec@1 75.781 (76.670)\n",
            "Epoch: [5][100/391]\tTime 0.035 (0.038)\tData 0.000 (0.004)\tLoss 0.6860 (0.6677)\tPrec@1 75.781 (76.493)\n",
            "Epoch: [5][150/391]\tTime 0.043 (0.037)\tData 0.000 (0.003)\tLoss 0.6457 (0.6664)\tPrec@1 77.344 (76.583)\n",
            "Epoch: [5][200/391]\tTime 0.030 (0.036)\tData 0.000 (0.003)\tLoss 0.6676 (0.6582)\tPrec@1 78.125 (76.955)\n",
            "Epoch: [5][250/391]\tTime 0.049 (0.035)\tData 0.000 (0.002)\tLoss 0.5711 (0.6515)\tPrec@1 78.906 (77.126)\n",
            "Epoch: [5][300/391]\tTime 0.026 (0.035)\tData 0.000 (0.002)\tLoss 0.6084 (0.6517)\tPrec@1 78.906 (77.214)\n",
            "Epoch: [5][350/391]\tTime 0.034 (0.035)\tData 0.000 (0.002)\tLoss 0.5574 (0.6504)\tPrec@1 78.906 (77.217)\n",
            "Test: [0/79]\tTime 0.182 (0.182)\tLoss 0.7831 (0.7831)\tPrec@1 74.219 (74.219)\n",
            "Test: [50/79]\tTime 0.023 (0.026)\tLoss 0.8538 (0.8501)\tPrec@1 70.312 (71.461)\n",
            " * Prec@1 71.590\n",
            "current lr 1.00000e-01\n",
            "Epoch: [6][0/391]\tTime 0.250 (0.250)\tData 0.197 (0.197)\tLoss 0.6808 (0.6808)\tPrec@1 76.562 (76.562)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0lfPJGTm2HV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tensorboard --logdir=runs/model1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7PLnqnqRb5K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "next(model.parameters()).is_cuda"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zz_Ft_po0RPR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(best_prec1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9C6h6IIfeIBX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(prec1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTPY9FNXk01l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchsummary import summary\n",
        "summary(model, (3, 32, 32))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}